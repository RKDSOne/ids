{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning On Imbalanced Data\n",
    "\n",
    "## Chinese Abstract\n",
    "不平衡数据上的机器学习。不平衡数据是指分类问题中某类数据的样本数量远小于其他类，这种数据在现实世界的应用中很常见。传统的分类器的设计大都建立在数据平衡的假设上，使得不平衡数据中少数类容易被忽视，得不到好的效果。  \n",
    "IDS已有很多现有工作，但大都集中在抽象的算法层面，缺少对适用场景的讨论。所以我打算从数据的角度出发，分析已有算法的原理，总结出什么样的数据适合什么样的算法，并通过实验验证，帮助其他工作结合自身数据特点，快速找到合适的方法。  \n",
    "这周想好了要讨论的几个点，\n",
    "\n",
    "## English Abstract\n",
    "**I**mbalanced **D**ata **S**et (IDS), which means the dataset with imbalanced proportion between different classes, arises in many real world applications. IDS problem is attracting growing attention, as traditional classifier such as `SVM`, `Decision Tree`, which assume that the training data is balanced and guarantee the overall accuracy, are not capable for IDS, especially when the imbalance rate goes up to $1:100$,$1:1000$ or even higher in some specific applications. \n",
    "Many approches have been proposed to solve this problem, while most of them focus on the model and results, there are few works conclude what to choose facing different applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menu\n",
    "- [Chinese Abstract](#Chinese-Abstract)  \n",
    "- [English Abstract](#English-Abstract)\n",
    "- [Menu](#Menu)\n",
    "- [Body](#Body)\n",
    "    - [Introduction](#Introduction)\n",
    "- [Conclusion](#Conclusion)\n",
    "- [References](#References)\n",
    "- [Copyright Declaration](#Copyright-Declaration)\n",
    "- [Acknowledge](#Acknowledge)\n",
    "- [Appendix](#Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Body\n",
    "### Introduction\n",
    "\n",
    "- Another category of existing works involves the modification in algorithm level, either using cost-sensitive learning or adapting ensembling methods. Algorithm level methods are \n",
    "    - Works focusing on algorithm level guarantee computational efficiency and convergence. However, imbalanced learning in algorithm level is based on some pre-defined objective functions, which might not be ideal for relavant applications.\n",
    "    - Need to adjust the params manually \n",
    "    - Existing methodologies are quite specialized with based on different principles[2], making it difficult to choose the ideal methodology.\n",
    "    - Some algorithm level methods can be difficult to implement, and most of them are \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The biggest challenge is revealed in methodology selection. Different methodologies make their assumptions and define their objective functions. ** HERE I CAN WRITE A DETAILED SURVEY LATTER IN CERTAIN CHARPTER **. Although we can categorize them by their assumptions to the data and their insights building objective functions, the problem still remains that, *how to analysis the dataset in hand so that we can find the target methodology?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The State-of-the-art solutions for imbalanced learning\n",
    "Existing works focus on specific algorithms, which can be mainly categorized into 3 ideas,\n",
    "\n",
    "- Sampling methods, \n",
    "- Ensemble methods, \n",
    "- Cost-sensitive learning, \n",
    "\n",
    "#### Sampling methods\n",
    "\n",
    "##### SMOTE\n",
    "\n",
    "##### mwMOTE\n",
    "\n",
    "\n",
    "#### Ensemble methods\n",
    "\n",
    "##### Easy Ensemble\n",
    "\n",
    "##### Balance Cascade\n",
    "\n",
    "#### Cost-sensitive learning\n",
    "\n",
    "##### Cost-sensitive Nerual Network\n",
    "\n",
    "#### The challenge and the future\n",
    "\n",
    "- Focus less on the nature of the data\n",
    "- Cannot tackle with all problems arises in IDS\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "We choose the artificially created data using Monte-Carlo simulation.\n",
    "\n",
    "\n",
    "\n",
    "### Methodology\n",
    "\n",
    "#### Distribution of minority data\n",
    "Small disjuncts are more likely to be misclassified. To descirbe how much the data is contained with small disjuncts, we propose the Within-Between Neighbor Ratio $r(x)$ for example $x$,\n",
    "$$r(x)=\\frac{\\sum _ {nn \\in NN(x)}{dis(x,nn)}} {\\sum _ {nn \\in NN _ {+}(x)}{dis(x,nn)}}$$\n",
    "\n",
    "##### Kernel Density Estimation\n",
    "To have an intuitive overview of the distribution of minority examples, which helps us to make decisions, we can estimate the Gaussian Kernel Density of $r(x)$ involving all examples in $X$.\n",
    "\n",
    "#### Overlapping between classes\n",
    "    *CITE [3] HERE*\n",
    "Overlapping can cause low performance in classification problems, which refers to the ambiguous regions in feature space where the prior probability is not considerablely dominated by any of the classes. The intrinsic problem of overlapping is the difficulty to determine the classification boundary. **Figure 1.** shows an example of overlap, **balabalabalabala**.  \n",
    "Together with class imbalance, overlap becomes more severe in classification tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptions for IDS\n",
    "With all the techniques above trying to solve the IDS problem, it is realized, however, that we cannot take all IDS problems the same.\n",
    "#### WBNR\n",
    "#### Overlap\n",
    "#### Proportion\n",
    "#### Minority Sample Size\n",
    "\n",
    "#### IDEA\n",
    "Given an IDS problem, when categorized by the descriptions mentioned above, the real challenge for the data set is revealed. In this way, we can find out the \"appropriate\" algorithm that can handle that challenge according to it's theory.\n",
    "\n",
    "- Overlap: OSS, mwMOTE\n",
    "- Small disjuncts: SMOTE\n",
    "- Rare Case Problems: One Class SVM, Mahalobis Distance (outlier detection)\n",
    "- Imbalance: Cost-sensitive Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "- Applications: \n",
    "\n",
    "#### Methods\n",
    "\n",
    "#### Experiment Settings\n",
    "\n",
    "#### Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "*\n",
    "[2] Stefanowski, Jerzy. \"Overlapping, rare examples and class decomposition in learning classifiers from imbalanced data.\" Emerging paradigms in machine learning. Springer Berlin Heidelberg, 2013. 277-306.  \n",
    "[3] Das, Biswajit, Narayanan C. Krishnan, and Diane J. Cook. \"Handling class overlap and imbalance to detect prompt situations in smart homes.\" Data Mining Workshops (ICDMW), 2013 IEEE 13th International Conference on. IEEE, 2013.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copyright Declaration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
